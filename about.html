<!DOCTYPE HTML>
<!--
	Faction by Pixelarity
	pixelarity.com | hello@pixelarity.com
	License: pixelarity.com/license
-->
<html>
	<head>
		<title>About ASL-LEX | ASL-LEX: A Lexical Database of American Sign Language</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="apple-touch-icon" sizes="180x180" href="images/favicon/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="images/favicon/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="images/favicon/favicon-16x16.png">
	</head>
	<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style>
	<body class="is-preload">

		<header id="header">

			<!-- Logo -->
				<span class="logo">
					<a href="index.html">ASL-LEX</a>
					<!--<span>By Pixelarity</span>-->
				</span>

			<!-- Nav -->
				<nav id="nav">
					<ul>
						<li><a href="index.html">Home</a></li>
						<li><a href="about.html">About ASL-LEX</a></li>
						<li><a href="instructions.html">Instructions</a></li>
						<li><a href="download.html">Download Data</a></li>
						<li><a href="publications.html">Publications</a></li>
						<li><a href="contact.html">Contact Us</a></li>
					</ul>
				</nav>

		</header>


		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
				<section class="info">


						<!-- Columns -->
						<div class="row gtr-200">

							<!-- Left Column -->
							<div class="col-6 col-12-medium">

								<header>
									<h1>About ASL-LEX</h1>
								</header>

								<!-- Text stuff -->
								<p>ASL-LEX is a database of lexical and phonological properties of American Sign Language signs.
								It was first released in 2016 with nearly 1,000 signs. ASL-LEX was updated in Fall 2020 with greatly expanded information and an increased size of 2,723 signs.
								</p>
								<p>ASL-LEX is available as a searchable web interface and as raw data in spreadsheet form. This website hosts the <a href="https://asl-lex.github.io/asl-lex/index.html">web visualization</a> and provides <a href="instructions.html">instructions</a> for how to use and <a href="download.html">download</a> the database.</p>

								<ul class="actions">
									<li><a href="visualization/index.html" class="button primary large icon fa-project-diagram" target="_new">View the Visualization</a></li>
									<li><a href="download.html" class="button primary large icon fa-download">Download the Data</a></li>

							</div>
							<!-- End Left Column -->

							<!-- Right Column -->
							<div class="col-6 col-12-medium">
								<div class='embed-container'><iframe src='https://www.youtube.com/embed/LPP6mFnH1xo' frameborder='0' allowfullscreen></iframe></div>
							</div>
							<!-- End Right Column -->
						</div>
						<!-- End Columns -->

						<!--<div class="table-wrapper">-->
						<h3>ASL-LEX 2.0 Contents</h3>
							<table class="alt">
								<colgroup>
	 								<col span="1" style="width: 15%;">
	 								<col span="1" style="width: 25%;">
	 								<col span="1" style="width: 60%;">
								</colgroup>
								<thead>
									<tr>
										<th>Name</th>
										<th>Description</th>
										<th>Notes</th>
									</tr>
								</thead>
								<tbody>
									<tr>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Frequency</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Subjective Frequency Ratings</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Ratings from 25 deaf signers/sign (native and early-exposed)</td>
									</tr>
									<tr>
										<td rowspan="2">Iconicity</td>
										<td>Iconicity Ratings</td>
										<td>Ratings from 29 deaf signers/sign for 993 signs; 28 hearing non-signers/sign for all signs</td>
									</tr>
									<tr>
										<td>Transparency Data</td>
										<td>Guess Accuracy and Transparency Ratings available for 430 signs, 20 hearing non-signers/sign</td>
									</tr>
									<tr>
										<td rowspan="3" style="background-color: rgba(144, 144, 144, 0.075);">Phonology</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Phonological Coding</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">23 features, including dominant and non-dominant handshape and sign complexity. Coding for multiple morphemes and reference images for handshape are also provided.</td>
									</tr>
									<tr>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Neighborhood Density</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Neighborhood Density - calculated using 15 features. Parameter Neighborhood Density - calculated using 3 primary parameters (Handshape, Major Location, Movement).
									</tr>
									<tr>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Phonotactic Probability</td>
										<td style="background-color: rgba(144, 144, 144, 0.075);">Sublexical Frequency - frequency of each sublexical phonological feature. Phonotactic Probability - mean of scaled sub-lexical features.</td>
									</tr>
									<tr>
										<td rowspan="3">Cross-Reference</td>
										<td>English Translations</td>
										<td>Available for 25% of signs</td>
									</tr>
									<tr>
										<td>Compatibility</td>
										<td>ASL Signbank, SLAAASh, and ASL-CDI 2.0</td>
									</tr>
									<tr>
										<td>ASL-CDI 2.0 Semantic Categories</td>
										<td></td>
									</tr>
									<tr style="background-color: rgba(144, 144, 144, 0.075);">
										<td>Videos</td>
										<td>Reference video for each sign</td>
										<td>All videos feature the same model against an identical background. Metadata also available: clip length, sign length, sign onset and sign offset</td>
									</td>
								</tbody>
							</table>
					<!--	</div>-->

						<h3>Articles</h3>
						<p>There are two articles that describe the procedures used to create the database and the 2.0 update. These articles report descriptive statistics for many sign properties and report analyses designed to more deeply understand how phonological, lexical, and semantic factors interact in the ASL lexicon.</p>
						<ul>
							<li>Sevcikova Sehyr, Z., Caselli, N., Cohen-Goldberg, A. M., & Emmorey, K. (2021). â€‹The ASL-LEX 2.0 Project: A database of lexical and phonological properties for 2,723 signs in American Sign Language. <i>Journal of Deaf Studies and Deaf Education</i>.</li>
							<li>Caselli, N., Sevcikova Sehyr, Z., Cohen-Goldberg, A. M., & Emmorey, K. (2017). ASL-LEX: A lexical database of American Sign Language. <i>Behavior Research Methods, 49</i>(2), 784-801. <a href="https://doi.org/10.3758/s13428-016-0742-0" target="_new">doi:10.3758/s13428-016-0742-0</a>.</li>
						</ul>

						<h3>Creators</h3>
						<!--<div class="about">-->
							<p>ASL-LEX is a collaboration between the <a href="https://emmoreylab.sdsu.edu/">Laboratory for Language and Cognitive Neuroscience</a> at <a href="https://www.sdsu.edu/">San Diego State University</a>, the <a href="https://www.bu.edu/sed/">Programs in Deaf Studies</a> at <a href="https://www.bu.edu/">Boston University</a>, and the <a href="https://ase.tufts.edu/psychology/psycholinglab/">Psycholinguistics and Linguistics Lab</a> at <a href="https://www.tufts.edu">Tufts University.</a></p>
						<!--</div>-->
						<div class="team">
							<article>
								<span class="image"><img src="images/naomi_caselli.png" alt="Naomi Caselli"></span>
								<p>
									<strong class="name">Naomi Caselli</strong>
									<span class="title">Wheelock College of Education, Boston University <br/><a href="http://sites.bu.edu/lexlab/">Visit Naomi's Website</a></span>
								</p>
							</article>
						</div>
						<div class ="team">
							<article>
								<span class="image"><img src="images/karen_emmorey.jpg" alt="Karen Emmorey"></span>
								<p>
									<strong class="name">Karen Emmorey</strong>
									<span class="title">School of Speech, Language, and Hearing Sciences<br/>San Diego State University<br/><a href="http://emmoreylab.sdsu.edu/">Visit Karen's Website</a></span>
								</p>
							</article>
						</div>
						<div class="team">
							<article>
								<span class="image"><img src="images/zed_sevcikova_sehyr.jpg" alt="Zed Sevicova Sehyr"></span>
								<p>
									<strong class="name">Zed Sevicova Sehyr</strong>
									<span class="title">School of Speech, Language, and Hearing Sciences<br/>San Diego State University<br/><a href="http://zedsehyr.weebly.com/">Visit Zed's Website</a></span>
								</p>
							</article>
						</div>
						<div class="team">
							<article>
								<span class="image"><img src="images/ariel_cohen-goldberg.png" alt="Ariel Cohen-Goldberg"></span>
								<p>
									<strong class="name">Ariel Cohen-Goldberg</strong>
									<span class="title">Dept of Psychology, Tufts University<br/><a href="https://ase.tufts.edu/psychology/psycholinglab/">Visit Ariel's Website</a></span>
								</p>
							</article>
						</div>
					</section>

				</div>
				<div class="inner">
					<section class="spotlights alt">
						<article>
						<h3>Thanks</h3>
						<p>Many thanks to Cindy O'Grady Farnady for modeling all of the signs and helping with data collection, to the Boston University Software & Application Innovation Lab (SAIL) at the <a href="https://www.bu.edu/hic/">Hariri Institute for Computing</a> (Shreya Pandit, Xinyun Cao, Jeff Simeon, Raj Vipani, Megan Fantes, Frederick Joossen, Fanonx Rogers, San Tran, Motunrola Bulomole, Andrei Lapets) for software development, and to Ben Tanen for his help developing the original visualizaiton for ASL-LEX 1.0. Thanks to Jennifer Feeney Petrich for her help in the initial stages of the project. Thanks also to Chelsea Hammond, Megan Canne, Anna Lim Frank, and Talia Cowen for their help coding the phonological properties.
					</article>

					<article>
						<h3>Funding</h3>
						<p>The original work on ASL-LEX was supported by the National Institutes of Health DC010997 to Dr. Karen Emmorey and San Diego State University, a Tufts University Faculty Research Award to Dr. Ariel Cohen-Goldberg, and a Tufts University Graduate Research Award to Dr. Naomi Caselli.</p>
						<p>Continuing work on ASL-LEX is supported by the <a href="https://www.nsf.gov/" target="_new">National Science Foundation</a>, <a href="https://www.nsf.gov/div/index.jsp?div=bcs" target="_new">Division of Behavioral and Cognitive Sciences</a>.</p>
						<ul>
							<li>NSF Awards BCS-1625954 and BCS-1918556 to Dr. Karen Emmorey</li>
							<li>NSF Award BCS-1918556 to Dr. Zed Zevcikova Sehyr</li>
							<li>NSF Awards BCS-1625793 and BCS-1918252 to Dr. Naomi Caselli</li>
							<li>NSF Awards BCS-1625761 and BCS-1918261 to Dr. Ariel Cohen-Goldberg</li>
						</ul>
					</article>
					</section>
				</div>

			</footer>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

			<!-- Google Analytics Script -->
			<script>
				(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
				(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
				m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

				ga('create', 'UA-54747354-2', 'auto');
				ga('send', 'pageview');

			</script>

	</body>
</html>
